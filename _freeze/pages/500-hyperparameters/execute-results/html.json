{
  "hash": "f459c92d40c8ce5f2a3f01a90ada0a41",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Choosing hyperparameters\n---\n\n\n\n\n\nAfter the exercise in the last chapter, you're hopefully thinking \"why am I spending my time trying different values of `n_neighbors`, can't it do this automatically?\" If so, you're in luck!\n\nIt is a very common thing to need to try out a bunch of different values for your hyperparameters and so scikit-learn provides us with some tools to help out.\n\nLet's do a similar thing to the last chapter, but load a different file this time. One with four different classes and follow through the usual steps:\n\n\n```python\nimport pandas as pd\n\ndata = pd.read_csv(\"https://bristol-training.github.io/applied_data_analysis_in_python/data/blobs.csv\")\nX = data[[\"x1\", \"x2\"]]\ny = data[\"y\"]\n```\n\n\n\n::: {#4b48c321 .cell execution_count=2}\n``` {.python .cell-code}\nimport seaborn as sns\n\nsns.scatterplot(data=data, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"Dark2\")\n```\n\n::: {.cell-output .cell-output-display}\n![](500-hyperparameters_files/figure-html/cell-3-output-1.png){width=596 height=432}\n:::\n:::\n\n\n::: {#01dd671d .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y)\n```\n:::\n\n\nThe tools that allows us to do the hyper-parameter searching is called [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/scikit-learn.model_selection.GridSearchCV.html) which will rerun the model training for every possible hyperparameter that we pass it.\n\nThe `GridSearchCV` constructor takes two things:\n 1. the model that we want to explore,\n 2. a dictionary containing the hyper-parameter values we want to test.\n\nIn this case, we are asking it to try every value of `n_neighbors` from 1 to 49 and it will use the training data to choose the best value.\n\n::: {#fe4436ff .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n\nhyperparameters = {\n    \"n_neighbors\" : range(1, 175),\n}\nmodel = GridSearchCV(KNeighborsClassifier(), hyperparameters)\nmodel.fit(train_X, train_y)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=KNeighborsClassifier(),\n             param_grid={&#x27;n_neighbors&#x27;: range(1, 175)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=KNeighborsClassifier(),\n             param_grid={&#x27;n_neighbors&#x27;: range(1, 175)})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: KNeighborsClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=36)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=36)</pre></div> </div></div></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\nThe best way to visualise the data is to plot it. We can do this by grabbing the `cv_results_` attribute of `GridSearchCV` and plotting the `mean_test_score` against the value of `n_neighbors`. `GridSearchCV` will run each experiment multiple times with different splits of training and validation data to provide some measure of uncertainty of the score:\n\n::: {#d7513859 .cell execution_count=5}\n``` {.python .cell-code}\ncv_results = pd.DataFrame(model.cv_results_)\ncv_results.plot.scatter(\"param_n_neighbors\", \"mean_test_score\", yerr=\"std_test_score\", figsize=(10,8))\n```\n\n::: {.cell-output .cell-output-display}\n![](500-hyperparameters_files/figure-html/cell-6-output-1.png){width=829 height=651}\n:::\n:::\n\n\nOne thing that `GridSearchCV` does, once it has scanned through all the parameters, is do a final fit using the whole training data set using the best hyperparameters from the search. This allows you to use the `GridSearchCV` object `model` as if it were a `KNeighborsClassifier` object.\n\n::: {#fee2e19d .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.inspection import DecisionBoundaryDisplay\n\nDecisionBoundaryDisplay.from_estimator(model, X, cmap=\"Pastel2\")\nsns.scatterplot(data=X, x=\"x1\", y=\"x2\", hue=y, palette=\"Dark2\")\n```\n\n::: {.cell-output .cell-output-display}\n![](500-hyperparameters_files/figure-html/cell-7-output-1.png){width=596 height=429}\n:::\n:::\n\n\nor use it directly with `predict`:\n\n::: {#013d5345 .cell execution_count=7}\n``` {.python .cell-code}\nnew_X = pd.DataFrame({\n    \"x1\": [0, -10, 5, -5],\n    \"x2\": [10, 5, 0, -10],\n})\n\nmodel.predict(new_X)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\narray([0, 3, 1, 2])\n```\n:::\n:::\n\n\nor measure its performance against the test data set:\n\n::: {#40de00d3 .cell execution_count=8}\n``` {.python .cell-code}\nmodel.score(test_X, test_y)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n0.904\n```\n:::\n:::\n\n\nUsing something like `GridSearchCV` allows you to find the best hyperparameters for your models while keeping them working most generally.\n\n\n\n\n\n::: {#exampleN .callout-note icon=false title='Exercise'}\nGrab the [Iris data set from sklearn](https://scikit-learn.org/stable/modules/generated/scikit-learn.datasets.load_iris.html). This time we will simplify it down to only two features (sepal length and sepal width) to simplity the visualisation.\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\nX, y = load_iris(as_frame=True, return_X_y=True)\nX = X[[\"sepal length (cm)\", \"sepal width (cm)\"]]  # Grab just two of the features\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n```\n\nUsing `GridSearchCV`, find the best value of `n_neighbors` and print the score of that model when run over the test data set.\n\n:::\n\n::: {#answerN .callout-caution icon=false title='Answer' collapse=\"true\"}\n\nAs usual, grab the data. The difference this time is that are only going to grab two of the features in order to make it a 2D problem which is easier to visualise.\n\n\n```python\nfrom pandas import DataFrame\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\nX = DataFrame(load_iris().data, columns=load_iris().feature_names)\nX = X[[\"sepal length (cm)\", \"sepal width (cm)\"]]  # Grab just two of the features\ny = load_iris().target\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n```\n\nWe will look at values of `n_neighbors` from 0 to 59.\n\n\n```python\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n\nhyperparameters = {\n    \"n_neighbors\" : range(1, 40),\n}\nclf = GridSearchCV(KNeighborsClassifier(), hyperparameters).fit(train_X, train_y)\n```\n\nTo easily look at the results, we put the output into a `DataFrame`, sort it by the test score (how well that value did against its validation set) and grab the top few rows.\n\n\n```python\ncv_results = DataFrame(clf.cv_results_)\ncv_results = cv_results.sort_values([\"rank_test_score\", \"mean_test_score\"])\ncv_results.head()[[\"param_n_neighbors\", \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]]\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_n_neighbors</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>0.795652</td>\n      <td>0.056227</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>0.795257</td>\n      <td>0.042471</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>0.786561</td>\n      <td>0.048231</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0.786561</td>\n      <td>0.048231</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>0.786561</td>\n      <td>0.048231</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nIt looks like the best one is `n_neighbors=31` but let's look on a plot to see how it varies:\n\n\n```python\ncv_results.plot.scatter(\"param_n_neighbors\", \"mean_test_score\", yerr=\"std_test_score\")\n```\n\n\n\n\n    <Axes: xlabel='param_n_neighbors', ylabel='mean_test_score'>\n\n\n\n\n    \n![](../img/answer_gridsearch_knn_iris_7_1.png)\n    \n\n\nIndeed `n_neighbors=31` is the best in the range but they all have large standard deviations. It's worth plotting it like this so that you might want to pick a lower mean in order to get a tighter distribution.\n\n\n```python\nfrom sklearn.inspection import DecisionBoundaryDisplay\nimport seaborn as sns\n\nDecisionBoundaryDisplay.from_estimator(clf, X, cmap=\"Pastel2\")\nsns.scatterplot(data=X, x=\"sepal length (cm)\", y=\"sepal width (cm)\", hue=y, palette=\"Dark2\")\n```\n\n\n\n\n    <Axes: xlabel='sepal length (cm)', ylabel='sepal width (cm)'>\n\n\n\n\n    \n![](../img/answer_gridsearch_knn_iris_9_1.png)\n    \n\n\n\n```python\nclf.score(test_X, test_y)\n```\n\n\n\n\n    0.868421052631579\n\n\n\n\n:::\n\n",
    "supporting": [
      "500-hyperparameters_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}